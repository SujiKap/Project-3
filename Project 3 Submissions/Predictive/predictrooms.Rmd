---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.0'
      jupytext_version: 1.0.5
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Testing Models

```{python}
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
```

```{python}
#Hypothesis : Can we predict room revenue with rooms sold and rate?

```

```{python}
#read data
df = pd.read_csv("C:/Users/kapali_s/Documents/SMU/Projects/Project_3/Project 3 Submissions/Predictive/dailydatapredidct.csv")
df.head()
```

```{python}
df = df.sort_values('rev', ascending = False).reset_index()
```

# Revenue and Rooms

```{python}
#plot
plt.scatter(df['rev'],df['rooms'],marker='o',c='blue')
plt.title("Revenue vs Rooms")
plt.xlabel("Revenue")
plt.ylabel("Rooms")
plt.show()

```

```{python}
df.hist(column = 'rev', bins=10)
```

```{python}
df.rev.describe()
pd.cut(df['rev'],10)
```

```{python}
df1 = df.dropna()
```

```{python}
#assign data to X and y
X = df1[["rooms"]].values
y = df1["rev"]
print(X.shape, y.shape)
```

```{python}
#create train and test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
```

```{python}
#create model using linear regression
from sklearn.linear_model import LinearRegression
model = LinearRegression()
```

```{python}
#X_train
```

```{python}
#fit the model
model.fit(X_train, y_train)
training_score = model.score(X_train, y_train)
testing_score = model.score(X_test, y_test)

### END SOLUTION 

print(f"Training Score Rev vs Rooms: {training_score}")
print(f"Testing Score Rev vs Rooms: {testing_score}")
```

```{python}
#plot residuals for training and test data
plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c="blue", label="Training Data")
plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c="orange", label="Testing Data")
plt.legend()
plt.hlines(y=0, xmin=y.min(), xmax=y.max())
plt.title("Residual Plot Rev vs Rooms")
```

# Revenue and Rate

```{python}
df.head()
```

```{python}
plt.scatter(df.loc[:,'rev'],df.loc[:,'rate'],marker='o',c='orange')
plt.title("Revenue vs Rate")
plt.xlabel("Revenue")
plt.ylabel("Rate")
plt.show()
```

```{python}
df.hist(column = 'rate', bins=10)
```

```{python}
dfSub = df[["rev", "rate"]]
```

```{python}
dfSub.corr()
```

```{python}
#assign data to X and y
X = df1[["rate"]]
y = df1["rev"].values.reshape(-1, 1)
print(X.shape, y.shape)
```

```{python}
#create train and test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)
```

```{python}
XTests = [x[0] for x in X_test.values]
YTests = [y[0] for y in y_test]
```

```{python}
testFrame = pd.DataFrame(list(zip(XTests, YTests)))
```

```{python}
testFrame
```

```{python}
testFrame.corr()
```

```{python}
# from sklearn.preprocessing import StandardScaler

# # Create a StandardScater model and fit it to the training data

# ### BEGIN SOLUTION
# X_scaler = StandardScaler().fit(X_train)
# y_scaler = StandardScaler().fit(y_train)

```

```{python}
# # Transform the training and testing data using the X_scaler and y_scaler models

# ### BEGIN SOLUTION
# X_train_scaled = X_scaler.transform(X_train)
# X_test_scaled = X_scaler.transform(X_test)
# y_train_scaled = y_scaler.transform(y_train)
# y_test_scaled = y_scaler.transform(y_test)
# ### END SOLUTION
```

```{python}
# # Create a LinearRegression model and fit it to the scaled training data

# ### BEGIN SOLUTION
# from sklearn.linear_model import LinearRegression
# model = LinearRegression()
# model.fit(X_train_scaled, y_train_scaled)
# ### END SOLUTION
```

```{python}
 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
```

```{python}
#  # Make predictions using the X_test_scaled data
# # Plot y_test_scaled vs y_test_scaled
# # Scatter plot y_test_scaled vs predictions

# ### BEGIN SOLUTION
# predictions = model.predict(X_test_scaled)
# model.fit(X_train_scaled, y_train_scaled)
# plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c="blue", label="Training Data")
# plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c="orange", label="Testing Data")
# plt.legend()
# plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())
# plt.title("Residual Plot")
# plt.show()
# ### END SOLUTION
```

```{python}
# # Used X_test_scaled, y_test_scaled, and model.predict(X_test_scaled) to calculate MSE and R2

# ### BEGIN SOLUTION
# from sklearn.metrics import mean_squared_error

# MSE = mean_squared_error(y_test_scaled, predictions)
# r2 = model.score(X_test_scaled, y_test_scaled)
# ### END SOLUTION

# print(f"MSE: {MSE}, R2: {r2}")
```

```{python}
# # LASSO model
# # Note: Use an alpha of .01 when creating the model for this activity
# from sklearn.linear_model import Lasso

# ### BEGIN SOLUTION
# lasso = Lasso(alpha=.01).fit(X_train_scaled, y_train_scaled)

# predictions = lasso.predict(X_test_scaled)

# MSE = mean_squared_error(y_test_scaled, predictions)
# r2 = lasso.score(X_test_scaled, y_test_scaled)
# ### END SOLUTION

# print(f"MSE: {MSE}, R2: {r2}")
```

```{python}
# # Ridge model
# # Note: Use an alpha of .01 when creating the model for this activity
# from sklearn.linear_model import Ridge

# ### BEGIN SOLUTION
# ridge = Ridge(alpha=.01).fit(X_train_scaled, y_train_scaled)

# predictions = ridge.predict(X_test_scaled)

# MSE = mean_squared_error(y_test_scaled, predictions)
# r2 = ridge.score(X_test_scaled, y_test_scaled)
# ### END SOLUTION

# print(f"MSE: {MSE}, R2: {r2}")
```

```{python}
#  # ElasticNet model
# # Note: Use an alpha of .01 when creating the model for this activity
# from sklearn.linear_model import ElasticNet

# ### BEGIN SOLUTION
# elasticnet = ElasticNet(alpha=.01).fit(X_train_scaled, y_train_scaled)

# predictions = elasticnet.predict(X_test_scaled)

# MSE = mean_squared_error(y_test_scaled, predictions)
# r2 = elasticnet.score(X_test_scaled, y_test_scaled)
# ### END SOLUTION

# print(f"MSE: {MSE}, R2: {r2}")
```

```{python}
# #create model using linear regression
# from sklearn.linear_model import LinearRegression
# model = LinearRegression()

```

```{python}
# #fit the model
# model.fit(X_train, y_train)
# training_score = model.score(X_train, y_train)
# testing_score = model.score(X_test, y_test)

# ### END SOLUTION 

# print(f"Training Score Rev vs Rate: {training_score}")
# print(f"Testing Score Rev vs Rate: {testing_score}")

```

```{python}
# #plot residuals for training and test data
# plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c="blue", label="Training Data")
# plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c="orange", label="Testing Data")
# plt.legend()
# plt.hlines(y=0, xmin=y.min(), xmax=y.max())
# plt.title("Residual Plot Room vs Rate")

```

# Try rooms and rate

```{python}
#assign data to X and y
X = df1[["rooms","rate"]]
y = df1["rev"].values.reshape(-1, 1)
print(X.shape, y.shape)
```

```{python}
#create train and test data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)
```

```{python}
from sklearn.preprocessing import StandardScaler

# Create a StandardScater model and fit it to the training data

### BEGIN SOLUTION
X_scaler = StandardScaler().fit(X_train)
y_scaler = StandardScaler().fit(y_train)
```

```{python}
# Transform the training and testing data using the X_scaler and y_scaler models

### BEGIN SOLUTION
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)
y_train_scaled = y_scaler.transform(y_train)
y_test_scaled = y_scaler.transform(y_test)
### END SOLUTION
```

```{python}
#create model using linear regression
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
model = LinearRegression()
#fit the model
model.fit(X_train, y_train)
```

```{python}
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
```

```{python}
# Make predictions using the X_test_scaled data
# Plot y_test_scaled vs y_test_scaled
# Scatter plot y_test_scaled vs predictions

### BEGIN SOLUTION
predictions = model.predict(X_test_scaled)
model.fit(X_train_scaled, y_train_scaled)
plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c="blue", label="Training Data")
plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c="orange", label="Testing Data")
plt.legend()
plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())
plt.title("Residual Plot")
plt.show()
### END SOLUTION
```

```{python}
model.fit(X_train, y_train)
training_score = model.score(X_train, y_train)
testing_score = model.score(X_test, y_test)

### END SOLUTION 

print(f"Training Score: {training_score}")
print(f"Testing Score : {testing_score}")
```

```{python}
#plot residuals for training and test data
plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c="blue", label="Training Data")
plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c="orange", label="Testing Data")
plt.legend()
plt.hlines(y=0, xmin=y.min(), xmax=y.max())
plt.title("Residual Plot ")
```

```{python}
#predict test data
y_pred = model.predict(X_test)

```

```{python}
y_pred
```

```{python}
df2 = pd.DataFrame(list(zip([y[0] for y in y_train], [y[0] for y in y_test])))
df2
```

```{python}
#evaluate the algorithm
from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

```{python}
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, np.repeat(np.average(y_test), len(y_test))))
print('Mean Squared Error:', metrics.mean_squared_error(y_test, np.repeat(np.average(y_test), len(y_test))))
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, np.repeat(np.average(y_test), len(y_test)))))
```

```{python}
from sklearn.ensemble import RandomForestRegressor
```

```{python}
y_train
```

```{python}
rf = RandomForestRegressor(n_estimators=200)
rf = rf.fit(X_train, y_train)
rf.score(X_test, y_test)
```

```{python}
sorted(zip(rf.feature_importances_, X_train.columns), reverse=True)
```

```{python}
from sklearn.ensemble import GradientBoostingRegressor
```

```{python}
gb = GradientBoostingRegressor(n_estimators=200)
gb = gb.fit(X_train, y_train)
gb.score(X_test, y_test)
```

```{python}
sorted(zip(gb.feature_importances_, X_train.columns), reverse=True)
```

```{python}
df1[["rooms","rev"]].corr()["rev"][0]
```

```{python}
df1[["rate","rev"]].corr()["rev"][0]
```

```{python}
import seaborn as sns
sns.heatmap(df1.corr())
```

```{python}

```
